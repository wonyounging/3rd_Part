{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) 로지스틱 회귀 모형의 penalty 부여 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   L1  오차의 절대값\n",
    "#   L2  오차의 제곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth    Name  Species\n",
       "0          5.1         3.5          1.4         0.2  setosa        0\n",
       "1          4.9         3.0          1.4         0.2  setosa        0\n",
       "2          4.7         3.2          1.3         0.2  setosa        0\n",
       "3          4.6         3.1          1.5         0.2  setosa        0\n",
       "4          5.0         3.6          1.4         0.2  setosa        0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"c:/workspace3/data/iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Name',\n",
       "       'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "\n",
    "X=df[cols]\n",
    "y=df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Species\n",
       "0    40\n",
       "1    40\n",
       "2    40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀계수들이 학습용 데이터에 과적합이 되지 않도록 정규화 요소를 더해주는 기법\n",
    "# 과적합이 발생할 수 있는 수치에 Penalty를 부여하는 방식\n",
    "# l1, l2, elasticnet, none\n",
    "# l1 : 오차의 절대값에 penalty 부여\n",
    "#  LASSO(Least Absolute Shrinkage Selector Operator) Penalty\n",
    "#  변수들이 많을 경우 실질적으로 영향을 미치는 변수의 개수는 적을 것이라는 가정\n",
    "#  영향이 적은 변수들을 0으로 보내서 없애고 영향력이 큰 변수들만 선택\n",
    "#  모형을 단순화시켜 해석이 용이함\n",
    "# l2 : 오차를 제곱한 값에 penalty 부여(일반적으로 사용하는 방식)\n",
    "#  Ridge Penalty\n",
    "#  변수들 간의 공선성 구조가 있을 때 사용\n",
    "#  공선성이 있을 경우 변수는 많지만 실제 사용가능한 정보는 적음\n",
    "#  변수들간의 분산을 감소시키는 기능\n",
    "# elasticnet : LASSO와 Ridge의 혼합형\n",
    "#   변수도 줄이고 분산도 줄이고 싶은 경우에 사용\n",
    "# none : penalty를 사용하지 않음\n",
    "# solver : 최적화(최적의 가중치를 설정)에 사용할 알고리즘( newton-cg, lbfgs, liblinear, sag, saga )\n",
    "#   lbfgs(Limited Memory Broyden–Fletcher–Goldfarb–Shanno) : 기본값\n",
    "#   liblinear : small dataset에 적합\n",
    "#   sag(Stochastic Average Gradient descent), saga(Variant of Sga) : big dataset에 적합\n",
    "#   newton-cg, saga, lbfgs : multi class 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(penalty='l1', random_state=0, solver='liblinear')\n",
      "학습용: 0.9583333333333334\n",
      "검증용: 0.9666666666666667\n",
      "\n",
      "LogisticRegression(max_iter=1000, random_state=0)\n",
      "학습용: 0.9666666666666667\n",
      "검증용: 1.0\n",
      "\n",
      "LogisticRegression(l1_ratio=1, max_iter=5000, penalty='elasticnet',\n",
      "                   random_state=0, solver='saga')\n",
      "학습용: 0.95\n",
      "검증용: 1.0\n",
      "\n",
      "LogisticRegression(penalty='none', random_state=0)\n",
      "학습용: 0.9833333333333333\n",
      "검증용: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.9.13\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rom sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(random_state=0, penalty='l1', solver='liblinear'),\n",
    "\n",
    "    #기본옵션\n",
    "    LogisticRegression(random_state=0, penalty='l2',max_iter=1000),\n",
    "    LogisticRegression(random_state=0, penalty='elasticnet', solver='saga', l1_ratio=1, max_iter=5000),\n",
    "    LogisticRegression(random_state=0, penalty='none')\n",
    "]    \n",
    "\n",
    "for logit in models:\n",
    "    print(logit)\n",
    "    logit.fit(X_train, y_train)\n",
    "    print(\"학습용:\",logit.score(X_train, y_train))\n",
    "    print(\"검증용:\",logit.score(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
