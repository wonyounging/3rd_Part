{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) 불균형 데이터셋 문제\n",
    "##### 1. 언더 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222014</td>\n",
       "      <td>0.540207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.347439</td>\n",
       "      <td>1.412824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.537238</td>\n",
       "      <td>0.372730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.134462</td>\n",
       "      <td>1.404819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.315827</td>\n",
       "      <td>1.356858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.440385</td>\n",
       "      <td>1.695643</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-0.790502</td>\n",
       "      <td>0.194243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.878130</td>\n",
       "      <td>0.829500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2.585933</td>\n",
       "      <td>1.927995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.123356</td>\n",
       "      <td>1.045755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a         b  y\n",
       "0     0.222014  0.540207  0\n",
       "1     1.347439  1.412824  0\n",
       "2     0.537238  0.372730  0\n",
       "3     2.134462  1.404819  0\n",
       "4     2.315827  1.356858  0\n",
       "...        ...       ... ..\n",
       "9995  2.440385  1.695643  0\n",
       "9996 -0.790502  0.194243  0\n",
       "9997  1.878130  0.829500  0\n",
       "9998  2.585933  1.927995  0\n",
       "9999  1.123356  1.045755  0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0, n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
    "\n",
    "dfX=pd.DataFrame(X,columns=['a','b'])\n",
    "dfy=pd.DataFrame(y,columns=['y'])\n",
    "\n",
    "df=pd.concat([dfX,dfy],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    9900\n",
       "1     100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = df[['a','b']] # 독립변수\n",
    "y1 = df[\"y\"]\n",
    "\n",
    "df[\"y\"].value_counts() #불균형 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2,  stratify=y1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용: 0.994125\n",
      "검증용: 0.995\n"
     ]
    }
   ],
   "source": [
    "#불균형 데이터셋으로 만든 모형\n",
    "\n",
    "model1 = LogisticRegression(random_state=0)\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "print(\"학습용:\",model1.score(X_train, y_train))\n",
    "print(\"검증용:\",model1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1980,    0],\n",
       "       [  10,   10]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred1=model1.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1980\n",
      "           1       1.00      0.50      0.67        20\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       1.00      0.75      0.83      2000\n",
      "weighted avg       1.00      0.99      0.99      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#소수 클래스의 정확도와 precision, precision,recall,f1-score 확인\n",
    "print(classification_report(y_test, pred1))\n",
    "\n",
    "# score는 0.9945로 높으나 recall의 경우 10/(10+10) = 0.5로 낮아지는 문제가 발생함\n",
    "#모형의 전반적인 정확도(accuracy)는 높지만 소수 클래스의 재현율(recall)이 0.5로 낮은 문제점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    5000\n",
       "1    5000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#균형 데이터\n",
    "\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0, n_clusters_per_class=1, flip_y=0, random_state=1)\n",
    "\n",
    "dfX=pd.DataFrame(X,columns=['a','b'])\n",
    "dfy=pd.DataFrame(y,columns=['y'])\n",
    "\n",
    "df2=pd.concat([dfX,dfy],axis=1)\n",
    "df2[\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df2[['a','b']] # 독립변수\n",
    "y2 = df2[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.2, stratify=y2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용: 0.896125\n",
      "검증용: 0.891\n"
     ]
    }
   ],
   "source": [
    "model2 = LogisticRegression(random_state=42)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "print(\"학습용:\",model2.score(X_train, y_train))\n",
    "print(\"검증용:\",model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      1000\n",
      "           1       0.90      0.87      0.89      1000\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.89      0.89      0.89      2000\n",
      "weighted avg       0.89      0.89      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred2=model2.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred2))\n",
    "#정확도와 재현율이 비슷하게 처리됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000, 2000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X1),len(y1),len(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#비대칭 데이터는 언더샘플링, 오버샘플링, 복합샘플링 등의 방법으로 데이터 비율을 맞추면 정밀도가 향상된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10000, n_features=2,  n_redundant=0, n_clusters_per_class=1, weights=[0.99],     flip_y=0, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#언더샘플링: 데이터의 손실이 크고 중요한 특성을 가진 데이터를 잃을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    100\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#무작위로 다수 클래스의 데이터를 없애는 단순 샘플링\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "X_sample, y_sample = RandomUnderSampler(random_state=0).fit_resample(X, y)\n",
    "X_samp = pd.DataFrame(data=X_sample,columns=['a','b'] )\n",
    "y_samp = pd.DataFrame(data=y_sample,columns=['y'])\n",
    "\n",
    "y_samp.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용: 0.8625\n",
      "검증용: 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.9.13\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_samp, y_samp, test_size=0.2, stratify=y_samp,random_state=10)\n",
    "\n",
    "model3 = LogisticRegression(random_state=42)\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "print(\"학습용:\",model3.score(X_train, y_train))\n",
    "print(\"검증용:\",model3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        20\n",
      "           1       0.90      0.95      0.93        20\n",
      "\n",
      "    accuracy                           0.93        40\n",
      "   macro avg       0.93      0.93      0.92        40\n",
      "weighted avg       0.93      0.93      0.92        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred3=model3.predict(X_test)\n",
    "print(classification_report(y_test, pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토멕링크(Tomek's link) : 서로 다른 클래스에 속하는 한쌍의 데이터\n",
    "\n",
    "#  토멕링크 중에서 다수 클래스에 속한 샘플을 제거함으로써 데이터의 균형을 맞추는 방법\n",
    "# 'majority': 다수 클래스의 샘플을 제거\n",
    "# 'not minority': 소수 클래스를 제외하고 샘플링\n",
    "# 'not majority': 다수 클래스를 제외하고 샘플링\n",
    "# 'all': 모든 클래스를 샘플링\n",
    "# 'auto': not minority와 같음(기본 옵션)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    9874\n",
       "1     100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "X_sample,y_sample=TomekLinks(sampling_strategy='majority').fit_resample(X, y)\n",
    "X_samp = pd.DataFrame(data=X_sample,columns=['a','b'] )\n",
    "y_samp = pd.DataFrame(data=y_sample,columns=['y'])\n",
    "\n",
    "y_samp.y.value_counts()\n",
    "#토멕링크 중에서 다수 클래스의 샘플들을 제거하는 방식, 1:1로 맞추는 방식은 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    187\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CNN(Condensed Nearest Neighbour) : 1-NN 모형으로 분류되지 않는 데이터만 남기는 방법\n",
    "\n",
    "#다수의 데이터 중에서 하나를 골라서 최근접 이웃이 다수 클래스이면 그 샘플을 빼는 방식\n",
    "#시간이 많이 걸림\n",
    "\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "\n",
    "X_sample, y_sample = CondensedNearestNeighbour(random_state=0).fit_resample(X, y)\n",
    "X_samp = pd.DataFrame(data=X_sample,columns=['a','b'] )\n",
    "y_samp = pd.DataFrame(data=y_sample,columns=['y'])\n",
    "\n",
    "y_samp.y.value_counts()\n",
    "#1:1로 맞춰지지는 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    6593\n",
       "1     100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Sided Selection\n",
    "\n",
    "# 토맥링크 방법과 Condensed Nearest Neighbour 방법을 섞은 방식\n",
    "# 토맥링크 중 다수 클래스의 샘플을 제거하고\n",
    "# 나머지 데이터 중에서도 서로 붙어있는 다수 클래스 데이터는 1-NN 방법으로 제외하는 방식\n",
    "\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "\n",
    "X_sample, y_sample = OneSidedSelection(random_state=0).fit_resample(X, y)\n",
    "X_samp = pd.DataFrame(data=X_sample,columns=['a','b'] )\n",
    "y_samp = pd.DataFrame(data=y_sample,columns=['y'])\n",
    "\n",
    "y_samp.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    9747\n",
       "1     100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ENN(Edited Nearest Neighbours)\n",
    "\n",
    "# 다수 클래스 데이터 중 소수 클래스와 가장 가까운 k(n_neighbors)개의 데이터가\n",
    "# 모두 또는 다수 클래스가 아니면 삭제하는 방법\n",
    "# 소수 클래스 주변의 다수 클래스 데이터는 삭제됨\n",
    "\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "#kind_sel='all' 모두, kind_sel='mode' 다수\n",
    "# 5개의 이웃이 모두 같은 클래스가 아니면 그 샘플을 제거함\n",
    "X_sample, y_sample= EditedNearestNeighbours(kind_sel=\"all\", n_neighbors=5).fit_resample(X, y)\n",
    "X_samp = pd.DataFrame(data=X_sample,columns=['a','b'] )\n",
    "y_samp = pd.DataFrame(data=y_sample,columns=['y'])\n",
    "\n",
    "y_samp.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    9721\n",
       "1     100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neighbourhood Cleaning Rule\n",
    "\n",
    "# CNN(Condensed Nearest Neighbour) 방법과 ENN(Edited Nearest Neighbours) 방법을 섞은 것\n",
    "\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "\n",
    "#kind_sel='all' 모두, kind_sel='mode' 다수\n",
    "X_sample,y_sample=NeighbourhoodCleaningRule(kind_sel=\"all\", n_neighbors=5).fit_resample(X, y)\n",
    "X_samp = pd.DataFrame(data=X_sample,columns=['a','b'] )\n",
    "y_samp = pd.DataFrame(data=y_sample,columns=['y'])\n",
    "\n",
    "y_samp.y.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
