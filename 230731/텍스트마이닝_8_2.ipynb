{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통계적 가중치 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "#긍정리뷰 100개 불러오기\n",
    "pos_review=(glob.glob(\"c:/workspace3/data/train/pos/*.txt\"))[0:100]\n",
    "\n",
    "lines_pos=[]\n",
    "\n",
    "for i in pos_review:\n",
    "    try:\n",
    "        f = open(i, 'r')\n",
    "        temp = f.readlines()[0]\n",
    "        lines_pos.append(temp)\n",
    "        f.close()\n",
    "    except :\n",
    "        continue\n",
    "\n",
    "len(lines_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4001)\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.06538462 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.23078109 0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tokenizer = RegexpTokenizer('[\\w]+')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#TF-IDF 가중치 할당\n",
    "vec = TfidfVectorizer(stop_words=stop_words)\n",
    "vector_lines_pos = vec.fit_transform(lines_pos)\n",
    "A=vector_lines_pos.toarray()\n",
    "\n",
    "print(A.shape)\n",
    "print(A)\n",
    "\n",
    "#x축 단어, y축 문서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4001, 100)\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.06538462 0.23078109]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#현재 상태는 100개의 문서의 유사도\n",
    "#단어간의 유사도를 구하는 것이 목적이므로\n",
    "#단어-문서 행렬로 변경\n",
    "#x축 문서, y축 단어\n",
    "\n",
    "A=A.transpose()\n",
    "\n",
    "print(A.shape)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.5\n",
      "  (1, 1)\t1.0\n",
      "  (2, 0)\t0.7\n",
      "  (2, 2)\t1.5\n",
      "[[0.5 0.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.7 0.  1.5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "#밀집행렬(dense array)\n",
    "a=np.array([[0.5,0,0],[0,1,0],[0.7,0,1.5]])\n",
    "\n",
    "#밀집행렬을 희소행렬(sparse array)로 변환\n",
    "#밀집행렬의 단점: 0이 많을 경우 메모리 낭비가 될 수 있음\n",
    "#희소행렬은 0이 아닌 값들의 위치와 값만 기록하여 메모리를 절약하는 방식\n",
    "b=sparse.csr_matrix(a)  \n",
    "print(b)\n",
    "\n",
    "# (0,0) 0.5 => 인덱스 0,0에 값 0.5\n",
    "# (1,1) 1 => 인덱스 1,1에 값 1\n",
    "# (2,0) 0.7 => 인덱스 2,0에 값 0.7\n",
    "# (2,2) 1 => 인덱스 2,2에 값 1.5\n",
    "\n",
    "c=b.toarray() #희소행렬을 밀집행렬로 변환\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((108, 1469), 0.37803585968894865),\n",
       " ((108, 1470), 0.2189685434746738),\n",
       " ((108, 1476), 0.06407477897013734),\n",
       " ((108, 1477), 0.185189577514238),\n",
       " ((108, 1480), 0.20111036876169444),\n",
       " ((108, 1489), 0.06995711757772019),\n",
       " ((108, 1496), 0.10714874067068783),\n",
       " ((108, 1503), 0.30487333830091773),\n",
       " ((108, 1504), 0.30487333830091773),\n",
       " ((108, 1512), 0.30487333830091773)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "A_sparse = sparse.csr_matrix(A)\n",
    "\n",
    "#코사인 유사도 계산\n",
    "similarities_sparse = cosine_similarity(A_sparse,dense_output=False)\n",
    "\n",
    "# todok() 행렬을 딕셔너리 형태로 변환\n",
    "list(similarities_sparse.todok().items())[35000:35010]\n",
    "\n",
    "#list(similarities_sparse.todok().items())[-10:]\n",
    "#단어 이름이 아닌 인덱스 형태로 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fraud'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1469,108), 0.37 1469 단어와 108 단어의 유사도는 37%\n",
    "vec.get_feature_names_out()[1469]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3372, 3971)</td>\n",
       "      <td>0.499961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3971, 3372)</td>\n",
       "      <td>0.499961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2554, 1192)</td>\n",
       "      <td>0.499958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1192, 2554)</td>\n",
       "      <td>0.499958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1321, 2468)</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(710, 2468)</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(2468, 710)</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2468, 1321)</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(889, 2146)</td>\n",
       "      <td>0.499909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2146, 889)</td>\n",
       "      <td>0.499909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          words    weight\n",
       "0  (3372, 3971)  0.499961\n",
       "1  (3971, 3372)  0.499961\n",
       "2  (2554, 1192)  0.499958\n",
       "3  (1192, 2554)  0.499958\n",
       "4  (1321, 2468)  0.499957\n",
       "5   (710, 2468)  0.499957\n",
       "6   (2468, 710)  0.499957\n",
       "7  (2468, 1321)  0.499957\n",
       "8   (889, 2146)  0.499909\n",
       "9   (2146, 889)  0.499909"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#위의 결과값을 데이터프레임으로 출력\n",
    "df=pd.DataFrame(list(similarities_sparse.todok().items()),columns=[\"words\",\"weight\"])\n",
    "\n",
    "df2=df.sort_values(by=['weight'],ascending=False)\n",
    "df2=df2.reset_index(drop=True)\n",
    "\n",
    "#단어 자신끼리의 짝은 1이 되므로 1보다 작은 항목들만 출력시킴\n",
    "df3=df2.loc[np.round(df2['weight']) < 1]\n",
    "df3=df3.reset_index(drop=True)\n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop,writers=>0.50\n",
      "writers,stop=>0.50\n",
      "past,essence=>0.50\n",
      "essence,past=>0.50\n",
      "farewell,older=>0.50\n",
      "concubine,older=>0.50\n",
      "older,concubine=>0.50\n",
      "older,farewell=>0.50\n",
      "deeply,made=>0.50\n",
      "made,deeply=>0.50\n",
      "watch,classes=>0.50\n",
      "classes,watch=>0.50\n"
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(df3.iterrows()):\n",
    "#                            개별행\n",
    "    a=vec.get_feature_names_out()[row[1][0][0]]\n",
    "    b=vec.get_feature_names_out()[row[1][0][1]]\n",
    "\n",
    "    print(f'{a},{b}=>{row[1][1]:.2f}')\n",
    "    \n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse array 희소행렬\n",
    "#               [1,1,1,1,1,1,0]\n",
    "\n",
    "#   dense array 밀집행렬\n",
    "#               [0,0,0,0,0,0,1] - 원핫인코딩\n",
    "\n",
    "# sparse array 희소표현\n",
    "#               (0,6) 1\n",
    "\n",
    "#   dense array 밀집표현\n",
    "#               [0,0,0,0,0,0,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
