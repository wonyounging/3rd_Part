{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.단어사전기반 분석 - 감성사전을 이용하여 각 단어의 감정 분류와 그 정도를 알 수 있어야 함\n",
    "#   텍스트와 감성지수가 사전에 정의되어 있어야 함\n",
    "\n",
    "import glob\n",
    "\n",
    "# ! pip install afinn\n",
    "from afinn import Afinn\n",
    "\n",
    "#imdb 데이터셋 5만건의 학습용,검증용 데이터셋 긍정,부정 리뷰로 라벨링되어 있음.\n",
    "#긍정리뷰데이터 20번째 내용\n",
    "# glob.glob 특정한 패턴의 파일만 선택하는 함수\n",
    "pos_review=(glob.glob(\"c:/workspace3/data/train/pos/*.txt\"))[20]\n",
    "\n",
    "f = open(pos_review)\n",
    "#파일을 읽음\n",
    "lines1 = f.readlines()[0]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Night Listener is better than people are generally saying. It has weaknesses, and it seems to be having a genre identity crisis, no doubt, but I think its creepy atmosphere and intriguing performances make up for this. The whole thing feels like one of those fireside \"this happened to a friend of a friend of mine\" ghost stories. One big complaint about the movie is the pacing: but the slow and sometimes awkward pacing is deliberate. Everything that unfolds in this movie is kept well within the realm of possibility, and real life just sort of plods along혰no? So there are no flashy endings or earth-shattering revelations, no \"showdown\" scenes. Thank Heaven. You have to get into the zone when watching this movie, forget your reservations and your expectations of what makes a (conventionally)good movie. Williams isn't terrific, but he easily meets the needs of the story, plus his character is supposed to be somewhat generic (\"No One\") as he is the Everyman, the avatar by which we ourselves enter the story. Toni Collette's performance should be nominated for an Oscar (even if she maybe shouldn't win it). Give it a shot. For quality and content alone, The Night Listener is surely in the top twenty percent of movies coming out these days.\n"
     ]
    }
   ],
   "source": [
    "print(lines1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#감성분석 객체\n",
    "afinn = Afinn()\n",
    "\n",
    "#텍스트 전처리 후 감성점수 산출\n",
    "afinn.score(lines1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/workspace3/data/train/pos\\\\0_9.txt',\n",
       " 'c:/workspace3/data/train/pos\\\\10000_8.txt',\n",
       " 'c:/workspace3/data/train/pos\\\\10001_10.txt',\n",
       " 'c:/workspace3/data/train/pos\\\\10002_7.txt',\n",
       " 'c:/workspace3/data/train/pos\\\\10003_8.txt',\n",
       " 'c:/workspace3/data/train/pos\\\\10004_8.txt',\n",
       " 'c:/workspace3/data/train/pos\\\\10005_7.txt',\n",
       " 'c:/workspace3/data/train/pos\\\\10006_7.txt',\n",
       " 'c:/workspace3/data/train/pos\\\\10007_7.txt',\n",
       " 'c:/workspace3/data/train/pos\\\\10008_7.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=list(glob.glob('c:/workspace3/data/train/pos/*.txt')[:10])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "2.0\n",
      "19.0\n",
      "3.0\n",
      "14.0\n",
      "8.0\n",
      "22.0\n",
      "28.0\n",
      "13.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "#학습용 긍정리뷰 10개 파일만 테스트\n",
    "\n",
    "afinn=Afinn() #감성분석 함수\n",
    "\n",
    "for i in files:\n",
    "    f=open(i) #파일 오픈\n",
    "    lines1=f.readlines()[0] #리스트의 첫번째 문자열\n",
    "    print(afinn.score(lines1)) #감성점수\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The characters are unlikeable and the script is awful. It's a waste of the talents of Deneuve and Auteuil.\n"
     ]
    }
   ],
   "source": [
    "#부정리뷰데이터 20번째 내용\n",
    "\n",
    "neg_review=(glob.glob(\"c:/workspace3/data/train/neg/*.txt\"))[20]\n",
    "f = open(neg_review)\n",
    "lines2 = f.readlines()[0]\n",
    "f.close()\n",
    "\n",
    "print(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afinn.score(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/workspace3/data/train/neg\\\\0_3.txt',\n",
       " 'c:/workspace3/data/train/neg\\\\10000_4.txt',\n",
       " 'c:/workspace3/data/train/neg\\\\10001_4.txt',\n",
       " 'c:/workspace3/data/train/neg\\\\10002_1.txt',\n",
       " 'c:/workspace3/data/train/neg\\\\10003_1.txt',\n",
       " 'c:/workspace3/data/train/neg\\\\10004_3.txt',\n",
       " 'c:/workspace3/data/train/neg\\\\10005_3.txt',\n",
       " 'c:/workspace3/data/train/neg\\\\10006_4.txt',\n",
       " 'c:/workspace3/data/train/neg\\\\10007_1.txt',\n",
       " 'c:/workspace3/data/train/neg\\\\10008_2.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=list(glob.glob('c:/workspace3/data/train/neg/*.txt')[:10])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "-4.0\n",
      "9.0\n",
      "5.0\n",
      "-7.0\n",
      "1.0\n",
      "13.0\n",
      "4.0\n",
      "7.0\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "#학습용 부정리뷰 10개 파일만 테스트\n",
    "\n",
    "afinn=Afinn() #감성분석 함수\n",
    "for i in files:\n",
    "    f=open(i) #파일 오픈\n",
    "    lines1=f.readlines()[0] #리스트의 첫번째 문자열\n",
    "    print(afinn.score(lines1)) #감성점수\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.기계학습으로 감성분석(시간이 매우 오래 걸림)\n",
    "\n",
    "import glob\n",
    "\n",
    "#긍정 텍스트 로딩\n",
    "pos_review=(glob.glob(\"c:/workspace3/data/train/pos/*.txt\")[:100])\n",
    "\n",
    "lines_pos=[]\n",
    "\n",
    "for i in pos_review:\n",
    "    try:\n",
    "        f = open(i)\n",
    "        temp = f.readlines()[0]\n",
    "        lines_pos.append(temp)\n",
    "        f.close()\n",
    "    except :\n",
    "        continue\n",
    "\n",
    "len(lines_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#부정 텍스트 로딩\n",
    "\n",
    "neg_review=(glob.glob(\"c:/workspace3/data/train/neg/*.txt\")[:100])\n",
    "\n",
    "lines_neg=[]\n",
    "\n",
    "for i in neg_review:\n",
    "    try:\n",
    "        f = open(i)\n",
    "        temp = f.readlines()[0]\n",
    "        lines_neg.append(temp)\n",
    "        f.close()\n",
    "    except :\n",
    "        continue\n",
    "\n",
    "len(lines_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#긍정,부정 리뷰를 합침\n",
    "\n",
    "total_text=lines_pos+lines_neg\n",
    "\n",
    "len(total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#긍정,부정 클래스 라벨링\n",
    "x = np.array([\"pos\", \"neg\"])\n",
    "class_Index=np.repeat(x, [len(lines_pos), len(lines_neg)], axis=0)\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어들에 Tfidf 가중치를 부여한 후 문서-단어 매트릭스로 바꿈\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(stop_words=stop_words).fit(total_text)\n",
    "\n",
    "X_train_vectorized = vect.transform(total_text)\n",
    "X_train_vectorized.index = class_Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bromwell</th>\n",
       "      <th>high</th>\n",
       "      <th>cartoon</th>\n",
       "      <th>comedy</th>\n",
       "      <th>ran</th>\n",
       "      <th>time</th>\n",
       "      <th>programs</th>\n",
       "      <th>school</th>\n",
       "      <th>life</th>\n",
       "      <th>teachers</th>\n",
       "      <th>...</th>\n",
       "      <th>zombified</th>\n",
       "      <th>auteur</th>\n",
       "      <th>ample</th>\n",
       "      <th>opportunities</th>\n",
       "      <th>golden</th>\n",
       "      <th>geist</th>\n",
       "      <th>uttered</th>\n",
       "      <th>downloading</th>\n",
       "      <th>midget</th>\n",
       "      <th>tricking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6530 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bromwell  high  cartoon  comedy  ran  time  programs  school  life  \\\n",
       "0       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "1       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "2       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "3       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "4       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "\n",
       "   teachers  ...  zombified  auteur  ample  opportunities  golden  geist  \\\n",
       "0       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "1       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "2       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "3       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "4       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "\n",
       "   uttered  downloading  midget  tricking  \n",
       "0      0.0          0.0     0.0       0.0  \n",
       "1      0.0          0.0     0.0       0.0  \n",
       "2      0.0          0.0     0.0       0.0  \n",
       "3      0.0          0.0     0.0       0.0  \n",
       "4      0.0          0.0     0.0       0.0  \n",
       "\n",
       "[5 rows x 6530 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#데이터프레임으로 변환\n",
    "\n",
    "df=pd.DataFrame(X_train_vectorized.toarray(), columns=vect.vocabulary_.keys())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 0.10070285188783222\n",
      "189 0.10070285188783222\n",
      "212 0.09513664322740871\n",
      "585 0.06603504311540802\n",
      "773 0.43419192948676516\n",
      "816 0.10070285188783222\n",
      "893 0.09081915636680153\n",
      "1038 0.07740781722251895\n",
      "1066 0.09513664322740871\n",
      "1105 0.0708975934136058\n",
      "1921 0.09081915636680153\n",
      "2034 0.0708975934136058\n",
      "2128 0.06498892497285297\n",
      "2174 0.10854798237169129\n",
      "2210 0.10070285188783222\n",
      "2727 0.3478134336932994\n",
      "2903 0.10070285188783222\n",
      "3008 0.10854798237169129\n",
      "3013 0.10854798237169129\n",
      "3249 0.07944638225969057\n",
      "3320 0.09081915636680153\n",
      "3387 0.049185844603996734\n",
      "3407 0.06831396493884356\n",
      "3563 0.04746484661907397\n",
      "3828 0.040035828354977356\n",
      "4031 0.031912297780574375\n",
      "4179 0.09081915636680153\n",
      "4242 0.10854798237169129\n",
      "4288 0.10070285188783222\n",
      "4358 0.10854798237169129\n",
      "4480 0.10070285188783222\n",
      "4487 0.10854798237169129\n",
      "4618 0.10070285188783222\n",
      "4664 0.09513664322740871\n",
      "4676 0.10854798237169129\n",
      "4757 0.09081915636680153\n",
      "4772 0.10070285188783222\n",
      "4872 0.06305246292974673\n",
      "4956 0.10854798237169129\n",
      "4992 0.10854798237169129\n",
      "5001 0.06498892497285297\n",
      "5020 0.1548156344450379\n",
      "5022 0.10854798237169129\n",
      "5037 0.10854798237169129\n",
      "5078 0.040035828354977356\n",
      "5273 0.07740781722251895\n",
      "5569 0.19027328645481742\n",
      "5570 0.21709596474338258\n",
      "5681 0.09081915636680153\n",
      "5758 0.43419192948676516\n",
      "5760 0.10854798237169129\n",
      "5847 0.04705749531070193\n",
      "5897 0.04031829282374757\n",
      "6032 0.08172530408312614\n",
      "6355 0.09513664322740871\n",
      "6380 0.06399647807823637\n",
      "6498 0.05490262579456099\n"
     ]
    }
   ],
   "source": [
    "for idx,value in enumerate(X_train_vectorized[0].toarray()[0]):  \n",
    "    if value>0:\n",
    "        print(idx, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#로지스틱 회귀 모형\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression(random_state=10)\n",
    "\n",
    "logit.fit(X_train_vectorized, class_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#긍정 리뷰들을 하나씩 불러와서 실험\n",
    "\n",
    "def pos_review(model):\n",
    "\n",
    "    count_all=0\n",
    "    count=0\n",
    "    num=100\n",
    "\n",
    "    tests1=[]\n",
    "\n",
    "    for idx in range(0,num):\n",
    "        pos_review_test=(glob.glob(\"c:/workspace3/data/test/pos/*.txt\"))[idx]\n",
    "        f = open(pos_review_test, 'r',encoding=\"utf-8\")\n",
    "        tests1.append(f.readlines())\n",
    "        f.close()\n",
    "\n",
    "    for test in tests1:\n",
    "        pred = model.predict(vect.transform(test))\n",
    "        result=pred[0]\n",
    "        if result==\"pos\":\n",
    "            count+=1\n",
    "        count_all += 1\n",
    "    rate= count*100/count_all\n",
    "\n",
    "    print(f\"긍정 분류정확도:{rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 분류정확도:66.0%\n",
      "부정 분류정확도:81.0%\n"
     ]
    }
   ],
   "source": [
    "#부정 리뷰들을 하나씩 불러와서 실험\n",
    "\n",
    "def neg_review(model):\n",
    "\n",
    "    count_all=0\n",
    "    count=0\n",
    "    num=100\n",
    "\n",
    "    tests2=[]\n",
    "\n",
    "    for idx in range(0,num):\n",
    "        neg_review_test=(glob.glob(\"c:/workspace3/data/test/neg/*.txt\"))[idx]\n",
    "        f = open(neg_review_test, 'r',encoding=\"utf-8\")\n",
    "        tests2.append(f.readlines())\n",
    "        f.close()\n",
    "\n",
    "    for test in tests2:\n",
    "        preds = model.predict(vect.transform(test))\n",
    "        result=preds[0]\n",
    "        if result==\"neg\":\n",
    "            count+=1\n",
    "        count_all+=1\n",
    "    rate= count*100/count_all\n",
    "\n",
    "    print(\"부정 분류정확도:{0:.1f}%\".format(rate))\n",
    "\n",
    "pos_review(logit)\n",
    "neg_review(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 분류정확도:39.0%\n",
      "부정 분류정확도:66.0%\n"
     ]
    }
   ],
   "source": [
    "#의사결정나무 모형\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "\n",
    "tree.fit(X_train_vectorized, class_Index)\n",
    "\n",
    "pos_review(tree)\n",
    "neg_review(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 분류정확도:44.0%\n",
      "부정 분류정확도:75.0%\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#10개의 트리로 구성된 랜덤 포레스트\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=10, random_state=10)\n",
    "\n",
    "forest.fit(X_train_vectorized, class_Index)\n",
    "\n",
    "pos_review(forest)\n",
    "neg_review(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 분류정확도:34.0%\n",
      "부정 분류정확도:85.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "knn.fit(X_train_vectorized, class_Index)\n",
    "\n",
    "pos_review(knn)\n",
    "neg_review(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 분류정확도:58.0%\n",
      "부정 분류정확도:79.0%\n"
     ]
    }
   ],
   "source": [
    "#인공신경망\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(random_state=10)\n",
    "\n",
    "mlp.fit(X_train_vectorized, class_Index)\n",
    "\n",
    "pos_review(mlp)\n",
    "neg_review(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 분류정확도:63.0%\n",
      "부정 분류정확도:87.0%\n"
     ]
    }
   ],
   "source": [
    "#SVM 모형\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(random_state=10)\n",
    "\n",
    "svm.fit(X_train_vectorized, class_Index)\n",
    "\n",
    "pos_review(svm)\n",
    "neg_review(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "#train = [ ('샌드위치 좋아해요', 'pos'), ('너무 좋은 곳이예요', 'pos'), ('너무 맛있어요', 'pos'), ('내가 제일 좋아하는 곳이예요', 'pos'), ('친한 친구예요', 'pos'), ('이 사람은 믿을 수 없어요', 'neg'), ('별로 안좋은 곳이네요', 'neg'), (\"맛이 별로네요\", 'neg'), ('경치가 별로예요', 'neg'), ('별로 볼게 없네요', 'neg') ]\n",
    "\n",
    "#test = [ ('최고의 음료수', 'pos'), ('별로 안좋아요', 'neg'), ('이번주는 컨디션이 안좋아요', 'neg'), ('너무 좋아요', 'pos'), ('나와 가장 친해요', 'pos'), (\"믿을 수 없어요\", 'neg') ]\n",
    "\n",
    "train = [\n",
    "    ('I love this sandwich.', 'pos'),\n",
    "    ('This is an amazing place!', 'pos'),\n",
    "    ('I feel very good about these beers.', 'pos'),\n",
    "    ('This is my best work.', 'pos'),\n",
    "    ('What an awesome view', 'pos'),\n",
    "    ('I do not like this restaurant', 'neg'),\n",
    "    ('I am tired of this stuff.', 'neg'),\n",
    "    (\"I can't deal with this\", 'neg'),\n",
    "    ('He is my sworn enemy!', 'neg'),\n",
    "    ('My boss is horrible.', 'neg')\n",
    "]\n",
    "\n",
    "test = [\n",
    "    ('The beer was good.', 'pos'),\n",
    "    ('I do not enjoy my job', 'neg'),\n",
    "    ('I am not feeling dandy today.', 'neg'),\n",
    "    ('I feel amazing!', 'pos'),\n",
    "    ('Gary is a friend of mine.', 'pos'),\n",
    "    (\"I can't believe I'm doing this.\", 'neg')\n",
    "]\n",
    "\n",
    "cl = NaiveBayesClassifier(train)\n",
    "\n",
    "#print(cl.classify('맛있는 음식이네요'))\n",
    "#print(cl.classify(\"피자맛이 별로네요\"))\n",
    "\n",
    "print(cl.classify('Their burgers are amazing'))  \n",
    "print(cl.classify(\"I don't like their pizza.\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#여러 문장을 종합하여 부정으로 분류\n",
    "#blob = TextBlob(\"맛있는 음식이네요. 피자는 별로네요. 서비스는 좋네요.\", classifier=cl)\n",
    "\n",
    "blob = TextBlob(\"The beer was amazing. But the hangover was horrible. My boss was not happy.\", classifier=cl)\n",
    "\n",
    "blob.classify()  # \"neg\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beer was amazing. ==> pos\n",
      "But the hangover was horrible. ==> neg\n",
      "My boss was not happy. ==> neg\n",
      "The beer was good. ==> pos\n",
      "I do not enjoy my job ==> neg\n",
      "I am not feeling dandy today. ==> neg\n",
      "I feel amazing! ==> pos\n",
      "Gary is a friend of mine. ==> neg\n",
      "I can't believe I'm doing this. ==> neg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#개별 문장으로 분류\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence, '==>', sentence.classify())\n",
    "\n",
    "# \"pos\", \"neg\", \"neg\"\n",
    "\n",
    "for row in test:\n",
    "    print(row[0],'==>', cl.classify(row[0]))\n",
    "\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(this) = True              neg : pos    =      2.3 : 1.0\n",
      "          contains(this) = False             pos : neg    =      1.8 : 1.0\n",
      "          contains(This) = False             neg : pos    =      1.6 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Informative Features\n",
    "#           contains(this) = True              neg : pos    =      2.3 : 1.0\n",
    "#           this가 포함된 경우 부정:긍정=2.3:1.0\n",
    "#           contains(this) = False             pos : neg    =      1.8 : 1.0\n",
    "#           this가 포함되지 않은 경우 긍정:부정=1.8:1.0\n",
    "#           contains(an) = False             neg : pos    =      1.6 : 1.0\n",
    "#           contains(This) = False             neg : pos    =      1.6 : 1.0\n",
    "#           contains(I) = True              neg : pos    =      1.4 : 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
