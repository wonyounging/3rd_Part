{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 전처리\n",
    "### 정수인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텍스트를 숫자로 바꾸는 기법\n",
    "\n",
    "text = '''모처럼 전국에 비가 내리고 있습니다.\n",
    "대부분 밤까지 계속되기 때문에 종일 우산이 필요하겠는데요.\n",
    "비의 양도 많고 바람도 강하게 불기 때문에 작은 우산 말고 큰 우산 챙기는 게 더 좋습니다.\n",
    "특히 제주와 남해안에서 비바람이 강합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['모처럼 전국에 비가 내리고 있습니다.', '대부분 밤까지 계속되기 때문에 종일 우산이 필요하겠는데요.', '비의 양도 많고 바람도 강하게 불기 때문에 작은 우산 말고 큰 우산 챙기는 게 더 좋습니다.', '특히 제주와 남해안에서 비바람이 강합니다.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# 문장 토큰화\n",
    "text = sent_tokenize(text)\n",
    "#       문장 나누기('.' 기준)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['모처럼', '전국', '비'],\n",
       " ['대부분', '밤', '계속', '때문', '종일', '우산'],\n",
       " ['비', '양도', '바람', '불기', '때문', '우산', '우산', '게', '더'],\n",
       " ['제주', '남해안', '비바람']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#명사만 추출하는 방법\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt=Okt()\n",
    "text2=[]\n",
    "\n",
    "for txt in text:\n",
    "    t=okt.nouns(txt)\n",
    "    #       명사\n",
    "    text2.append(t)    \n",
    "text2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['모처럼', '전국', '비', '있습니다'], ['대부분', '밤', '계속', '때문', '종일', '우산', '필요하겠는데요'], ['비', '양도', '많고', '바람', '강하게', '불기', '때문', '작은', '우산', '우산', '게', '더', '좋습니다'], ['제주', '남해안', '비바람', '강합니다']]\n"
     ]
    }
   ],
   "source": [
    "# 명사와 형용사를 추출하는 방법\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt=Okt()\n",
    "text2 = []\n",
    "\n",
    "for txt in text:\n",
    "    morph = okt.pos(txt)\n",
    "    text2.append(morph)\n",
    "\n",
    "text3 = []\n",
    "\n",
    "for text in text2:\n",
    "    line=[]\n",
    "    \n",
    "    for word, tag in text:\n",
    "        if tag in ['Noun','Adjective']:\n",
    "            #       명사,    형용사\n",
    "            line.append(word)\n",
    "    text3.append(line)\n",
    "print(text3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['모처럼', '전국', '비', '있습니다'], ['대부분', '밤', '계속', '때문', '종일', '우산', '필요하겠는데요'], ['비', '양도', '많고', '바람', '강하게', '불기', '때문', '작은', '우산', '우산', '좋습니다'], ['제주', '남해안', '비바람', '강합니다']]\n"
     ]
    }
   ],
   "source": [
    "vocab = {}\n",
    "sentences = []\n",
    "stop_words = ['더', '게']\n",
    "\n",
    "for txt in text3:\n",
    "    result = []\n",
    "    \n",
    "    for word in txt:\n",
    "        # 불용어 제거\n",
    "        if word not in stop_words: #불용어가 아니면\n",
    "            result.append(word)\n",
    "            if word not in vocab: #새로운 단어이면\n",
    "                vocab[word] = 0 # 출현횟수 0으로\n",
    "            vocab[word] += 1 #출현횟수 증가\n",
    "    sentences.append(result)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'모처럼': 1, '전국': 1, '비': 2, '있습니다': 1, '대부분': 1, '밤': 1, '계속': 1, '때문': 2, '종일': 1, '우산': 3, '필요하겠는데요': 1, '양도': 1, '많고': 1, '바람': 1, '강하게': 1, '불기': 1, '작은': 1, '좋습니다': 1, '제주': 1, '남해안': 1, '비바람': 1, '강합니다': 1}\n"
     ]
    }
   ],
   "source": [
    "#단어:출현빈도\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(vocab[\"우산\"]) # 단어의 빈도수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'비': 1, '때문': 2, '우산': 3}\n"
     ]
    }
   ],
   "source": [
    "#단어에 일련번호 부여\n",
    "\n",
    "word_to_index = {}\n",
    "i=0\n",
    "\n",
    "for word in vocab :\n",
    "    if vocab[word] > 1 : # 빈도수가 1보다 큰 단어들만 추가\n",
    "        i=i+1\n",
    "        word_to_index[word] = i #단어에 번호를 매김\n",
    "        \n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 4, 1, 4], [4, 4, 4, 2, 4, 3, 4], [1, 4, 4, 4, 4, 4, 2, 4, 3, 3, 4], [4, 4, 4, 4]]\n"
     ]
    }
   ],
   "source": [
    "#Out-Of-Vocabulary 단어 집합에 없는 단어\n",
    "#출현빈도수가 낮은 단어들은 word_to_index에 없으므로\n",
    "# word_to_index에 OOV라는 단어를 추가하고 단어 집합에 없는 단어들은 OOV로 처리\n",
    "\n",
    "word_to_index['OOV'] = len(word_to_index) + 1\n",
    "encoded = []\n",
    "\n",
    "for s in sentences: #문장들을 반복\n",
    "    temp = []\n",
    "\n",
    "    for w in s: #문장의 단어들을 반복\n",
    "        try:\n",
    "            #단어의 고유번호를 리스트에 추가\n",
    "            temp.append(word_to_index[w])\n",
    "        except:\n",
    "            #존재하지 않는 단어는 OOV의 인덱스를 추가\n",
    "            temp.append(word_to_index['OOV'])\n",
    "    encoded.append(temp)\n",
    "\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['모처럼' '전국' '비' '있습니다' '대부분' '밤' '계속' '때문' '종일' '우산' '필요하겠는데요' '비' '양도'\n",
      " '많고' '바람' '강하게' '불기' '때문' '작은' '우산' '우산' '좋습니다' '제주' '남해안' '비바람' '강합니다']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#2차원 데이터를 1차원으로 바꾸고\n",
    "words = np.hstack(sentences)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'우산': 3, '비': 2, '때문': 2, '모처럼': 1, '전국': 1, '있습니다': 1, '대부분': 1, '밤': 1, '계속': 1, '종일': 1, '필요하겠는데요': 1, '양도': 1, '많고': 1, '바람': 1, '강하게': 1, '불기': 1, '작은': 1, '좋습니다': 1, '제주': 1, '남해안': 1, '비바람': 1, '강합니다': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab = Counter(words) # 단어의 출현빈도를 쉽게 계산하는 클래스\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(vocab[\"우산\"]) # 단어의 빈도수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('우산', 3), ('비', 2), ('때문', 2), ('모처럼', 1), ('전국', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "\n",
    "# 출현빈도가 높은 상위 5개의 단어\n",
    "\n",
    "vocab = vocab.most_common(vocab_size)\n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'우산': 1, '비': 2, '때문': 3, '모처럼': 4, '전국': 5}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "\n",
    "i = 0\n",
    "\n",
    "for (word, frequency) in vocab :\n",
    "    i = i+1\n",
    "    word_to_index[word] = i\n",
    "\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   단어 출현빈도\n",
    "#   문서1       문서2       문서3       문서4       ...\n",
    "#   날씨        날씨        날씨        날씨\n",
    "\n",
    "#   tf(하나의 문서에서 나타나는 단어)\n",
    "\n",
    "#   df(문서마다 나타나는 단어)\n",
    "\n",
    "\n",
    "#   정수 인코딩 단점 : 순서가 없음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
